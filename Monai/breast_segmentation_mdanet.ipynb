{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "345e96a1",
   "metadata": {},
   "source": [
    "# Breast Tumor in Ultrasound 2D Segmentation with MONAI\n",
    "\n",
    "1. Transforms for dictionary format data.\n",
    "1. Load Nifti image with metadata.\n",
    "1. Cache IO and transforms to accelerate training and validation.\n",
    "1. 2D UNet model, Dice loss function, Mean Dice metric for 2D segmentation task.\n",
    "1. Deterministic training for reproducibility.\n",
    "\n",
    "Target: Breast Tumor  \n",
    "Modality: Ultrasound  \n",
    "Dataset: 2D images in NII (80% Training + 10% Validation + 10% Testing)\n",
    "\n",
    "### MDA-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76eded7",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64261c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[gdown, nibabel, tqdm]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    "    \n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandGaussianNoised,\n",
    "    RandGaussianSmoothd,\n",
    "    RandAdjustContrastd,\n",
    "    RandZoomd,\n",
    "    RandGridDistortiond,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "from monai.data.utils import pad_list_data_collate\n",
    "import pdb\n",
    "import torch.nn as nn\n",
    "import nibabel as nib\n",
    "\n",
    "from MDANet import MDA_Net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f53eda",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9122e26b",
   "metadata": {},
   "source": [
    "## Dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f0a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/users/jvilaca/raul/3_2_CBIS_Croped_padding\"\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34f3534",
   "metadata": {},
   "source": [
    "## Set Breast Ultrasound dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bacb993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
    "train_labels = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
    "train_files = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images, train_labels)\n",
    "]\n",
    "\n",
    "\n",
    "#Val\n",
    "val_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesVl\", \"*.nii.gz\")))\n",
    "val_labels = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"labelsVl\", \"*.nii.gz\")))\n",
    "val_files = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(val_images, val_labels)\n",
    "]\n",
    "\n",
    "#Test\n",
    "test_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTs\", \"*.nii.gz\")))\n",
    "test_labels = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"labelsTs\", \"*.nii.gz\")))\n",
    "test_files = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(test_images, test_labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c12919",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204732db",
   "metadata": {},
   "source": [
    "## Set deterministic training for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275938d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e97c2",
   "metadata": {},
   "source": [
    "## Setup transforms for training and validation\n",
    "\n",
    "Here we use several transforms to augment the dataset:\n",
    "1. `LoadImaged` loads the spleen CT images and labels from NIfTI format files.\n",
    "1. `AddChanneld` as the original data doesn't have channel dim, add 1 dim to construct \"channel first\" shape.\n",
    "1. `Spacingd` adjusts the spacing by `pixdim=(1.5, 1.5, 2.)` based on the affine matrix.\n",
    "1. `Orientationd` unifies the data orientation based on the affine matrix.\n",
    "1. `ScaleIntensityRanged` extracts intensity range [-57, 164] and scales to [0, 1].\n",
    "1. `CropForegroundd` removes all zero borders to focus on the valid body area of the images and labels.\n",
    "1. `RandCropByPosNegLabeld` randomly crop patch samples from big image based on pos / neg ratio.  \n",
    "The image centers of negative samples must be in valid body area.\n",
    "1. `RandAffined` efficiently performs `rotate`, `scale`, `shear`, `translate`, etc. together based on PyTorch affine transform.\n",
    "1. `EnsureTyped` converts the numpy array to PyTorch Tensor for further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68086106",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0, a_max=255,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        \n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        RandScaleIntensityd(keys=\"image\", factors=0.5, prob=0.5),\n",
    "        RandShiftIntensityd(keys=\"image\", offsets=0.5, prob=0.5),\n",
    "        RandGaussianNoised(keys=\"image\", prob=0.5, mean=0.0, std=0.05),\n",
    "        RandGaussianSmoothd(keys=\"image\", prob=0.25),\n",
    "        RandAdjustContrastd(keys=\"image\", prob=0.5, gamma=(0.5,2.5)),\n",
    "        RandZoomd(keys=[\"image\", \"label\"], prob=0.5, min_zoom=1, max_zoom=1.3),\n",
    "        RandGridDistortiond(keys=[\"image\", \"label\"], prob=0.5, distort_limit=(-0.2,0.2)),\n",
    "\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0, a_max=255,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0, a_max=255,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f20e399",
   "metadata": {},
   "source": [
    "## Check transforms in DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f5671",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "# plot the slice [:, :, 80]\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c79d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c987d0",
   "metadata": {},
   "source": [
    "## Define CacheDataset and DataLoader for training and validation\n",
    "\n",
    "Here we use CacheDataset to accelerate training and validation process, it's 10x faster than the regular Dataset.  \n",
    "To achieve best performance, set `cache_rate=1.0` to cache all the data, if memory is not enough, set lower value.  \n",
    "Users can also set `cache_num` instead of `cache_rate`, will use the minimum value of the 2 settings.  \n",
    "And set `num_workers` to enable multi-threads during caching.  \n",
    "If want to to try the regular Dataset, just change to use the commented code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CacheDataset(\n",
    "    data=train_files, transform=train_transforms,\n",
    "    cache_rate=1.0, num_workers=4)\n",
    "# train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=10, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "val_ds = CacheDataset(\n",
    "    data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=0)\n",
    "# val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=5, num_workers=4)\n",
    "\n",
    "\n",
    "test_ds = CacheDataset(\n",
    "    data=test_files, transform=test_transforms, cache_rate=1.0, num_workers=0)\n",
    "# val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902bb7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters etc.\n",
    "#DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "NUM_EPOCHS = 5000\n",
    "#LOAD_MODEL = False\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "\n",
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    #loop = tqdm(loader)\n",
    "    \n",
    "    for batch_data in loader:\n",
    "        #data = data.to(device=DEVICE)\n",
    "        #targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device=DEVICE),\n",
    "            batch_data[\"label\"].to(device=DEVICE).unsqueeze(1),\n",
    "            )\n",
    "        dims = np.shape(inputs)\n",
    "        inputs = torch.reshape(inputs,[dims[0],1,dims[2],dims[3]])\n",
    "        print(np.shape(inputs))\n",
    "        labels = torch.reshape(labels,[dims[0],1,dims[2],dims[3]])\n",
    "        #print(np.shape(labels))\n",
    "        \n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(inputs)\n",
    "            loss = loss_fn(predictions, labels)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # update tqdm loop\n",
    "        # loader.set_postfix(loss=loss.item())\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c271126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, device, loss_fn):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in loader:\n",
    "            inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device).unsqueeze(1),\n",
    "            )\n",
    "            dims = np.shape(inputs)        \n",
    "            inputs = torch.reshape(inputs,[dims[0],1,dims[2],dims[3]])\n",
    "            # print(np.shape(inputs))\n",
    "            labels = torch.reshape(labels,[dims[0],1,dims[2],dims[3]])\n",
    "            # print(np.shape(labels))\n",
    "            #x = x.to(device)\n",
    "            #y = y.to(device).unsqueeze(1)\n",
    "            preds = torch.sigmoid(model(inputs))\n",
    "            preds = (preds > 0.5).float()\n",
    "            num_correct += (preds == labels).sum()\n",
    "            num_pixels += torch.numel(preds)\n",
    "            dice_score += (2 * (preds * labels).sum()) / (\n",
    "                (preds + labels).sum() + 1e-8\n",
    "            )\n",
    "            \n",
    "             # forward\n",
    "            with torch.cuda.amp.autocast():\n",
    "                predictions = model(inputs)\n",
    "                loss = loss_fn(predictions, labels)\n",
    "\n",
    "    print(\n",
    "        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n",
    "    )\n",
    "    print(f\"Dice score: {dice_score/len(loader)}\")\n",
    "\n",
    "    dice = dice_score/len(loader)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return dice, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18a71af",
   "metadata": {},
   "source": [
    "## Create root path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271495b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"/home/users/jvilaca/raul/Methods/MDA-UNet\"\n",
    "mes_ext = {1: 'Jan', 2 : 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May',6:'Jun',7:'Jul', 8:'Aug',9:'Sep', 10: 'Oct', 11:'Nov', 12:'Dec'}\n",
    "month = time.strftime(\"%m\")\n",
    "time_str = time.strftime(\"%d_%H-%M-%S\")\n",
    "filename = mes_ext[int(month)]+time_str;\n",
    "\n",
    "path = os.path.join(parent_dir, filename)\n",
    "os.mkdir(path)\n",
    "\n",
    "root_dir = path\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bf88ec",
   "metadata": {},
   "source": [
    "# Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044d9c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MDA_Net(img_ch=1, output_ch=1).to(DEVICE)\n",
    "#loss_fn = nn.BCEWithLogitsLoss()\n",
    "loss_fn = DiceCELoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "\n",
    "# if LOAD_MODEL:\n",
    "#     checkpoint = torch.load(\"my_checkpoint.pth.tar\")\n",
    "#     print(\"=> Loading checkpoint\")\n",
    "#     model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "# pdb.set_trace()\n",
    "check_accuracy(val_loader, model, DEVICE, loss_fn)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    print(str(epoch) + '/' + str(NUM_EPOCHS) + ' epochs')\n",
    "\n",
    "    loss = train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "    print('Loss: ' + str(loss))\n",
    "    writer.add_scalar(\"Loss/train\", loss, epoch+1)\n",
    "    \n",
    "    # save model\n",
    "    # checkpoint = {\n",
    "    #     \"state_dict\": model.state_dict(),\n",
    "    #     \"optimizer\":optimizer.state_dict(),\n",
    "    # }\n",
    "    #print(\"=> Saving checkpoint\")\n",
    "    # torch.save(checkpoint, \"my_checkpoint.pth\")\n",
    "    \n",
    "    # check accuracy\n",
    "    dice, loss_val = check_accuracy(val_loader, model, DEVICE, loss_fn)\n",
    "    print('Dice: ' + str(dice))\n",
    "    writer.add_scalar(\"Dice/val\", dice, epoch+1)\n",
    "    \n",
    "    print('Loss: ' + str(loss))\n",
    "    writer.add_scalar(\"Loss/val\", loss_val, epoch+1)\n",
    "    \n",
    "    metric = dice\n",
    "    \n",
    "    if metric > best_metric:\n",
    "        best_metric = metric\n",
    "        best_metric_epoch = epoch + 1\n",
    "        torch.save({'model': model.state_dict(),'epoch': epoch+1,'optimizer': optimizer.state_dict()}, os.path.join(\n",
    "            root_dir, \"best_metric_model.pth\"))\n",
    "        print(\"=> Saving best metric model checkpoint\")\n",
    "        \n",
    "    # print some examples to a folder\n",
    "    #save_predictions_as_imgs(\n",
    "    #    val_loader, model, folder=\"saved_images/\", device=DEVICE)\n",
    "    \n",
    "torch.save({'model': model.state_dict(),'epoch': epoch+1,'optimizer': optimizer.state_dict()}, os.path.join(\n",
    "                root_dir, \"final_metric_model.pth\"))\n",
    "print(\"=> Saving final metric model checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf24c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"train completed, best_metric: {best_metric:.4f} \"\n",
    "    f\"at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5430fc",
   "metadata": {},
   "source": [
    "# Testing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a03a83",
   "metadata": {},
   "source": [
    "## Load model and save prediction masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b10af-4588-42f3-8e47-861dc4701eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"/home/users/jvilaca/raul/Methods/MDA-UNet/Jan04_18-32-41\"\n",
    "pathSave = root_dir + \"/predLabelsSig\"\n",
    "os.mkdir(pathSave)\n",
    "pathSave = pathSave + \"/\"\n",
    "pathSave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b6196-1b71-4e12-9f38-661e0175ac1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_name = \"final_metric_model.pth\"\n",
    "model_name = \"best_metric_model.pth\"\n",
    "\n",
    "checkpoint = torch.load(os.path.join(root_dir , model_name))\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "model.eval()\n",
    "i = 0\n",
    "sig=nn.Sigmoid()\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_inputs, test_labels = (\n",
    "            test_data[\"image\"].to(device=DEVICE),\n",
    "            test_data[\"label\"].to(device=DEVICE),\n",
    "        )\n",
    "        dimsTest = np.shape(test_inputs)\n",
    "        test_inputs = torch.reshape(test_inputs,[dimsTest[0],1,dimsTest[2],dimsTest[3]])\n",
    "        test_labels = torch.reshape(test_labels,[dimsTest[0],1,dimsTest[2],dimsTest[3]])\n",
    "        kk = model(test_inputs)\n",
    "        kk = sig(kk)\n",
    "#         kk=kk[0]\n",
    "        kk = torch.where(kk>0.90, 1, 0)\n",
    "        kk = np.expand_dims(kk[0,0,:,:].cpu().detach().numpy(), axis = 2) \n",
    "        name = test_files[i]['image']\n",
    "        masknii = nib.load(name)  \n",
    "        m = masknii.affine\n",
    "        header = masknii.header\n",
    "        predicted = nib.Nifti1Image(kk, m, header)\n",
    "        nib.save(predicted, pathSave + name.split('/')[-1])\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb779de-028f-46a2-8eb5-57e02bbad704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the slice [:, :, 80]\n",
    "plt.figure(\"check\", (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(f\"image\")\n",
    "plt.imshow(test_inputs[0, 0, :, :].cpu().detach().numpy(), cmap=\"gray\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(f\"label\")\n",
    "plt.imshow(test_labels[0, 0, :, :].cpu().detach().numpy(), cmap=\"gray\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(f\"output\")\n",
    "plt.imshow(kk[:, :, 0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b0273-925e-44ca-9b8a-5dc800514b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
